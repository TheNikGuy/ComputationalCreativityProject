# Computational Creativity Project

In recent years, StyleGAN (a Generative Adversarial Network) and 
its variants have established themselves as the image generators of convincing 
human portraits. But all the generated faces are non-existing humans. In this 
study, an attempt has been made to use the ability of StyleGAN of generating a 
lifelike portrait to develop a real face guided by human input. In this work, 
Contrastive-Language-Image-Pretraining (CLIP) is used in order to develop a 
text-driven interface for StyleGAN image manipulation. First, the method used 
to generate a face by showing user options of facial features and taking their 
input is described, and its results are presented. Later, which approach worked, 
and which didn't are discussed. Finally, future improvements are suggested to 
this amateur effort.
